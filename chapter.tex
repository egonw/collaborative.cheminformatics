\documentclass[12pt]{book}

\newcommand{\refname}{}

\usepackage[utf8]{inputenc}
%\usepackage{a4wide}
\usepackage{bibspacing}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{times}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{ctable}


\begin{document}

\chapter{Collaborative Cheminformatics Applications}

\begin{LARGE}
Rajarshi Guha, Ola Spjuth, Egon Willighagen
\end{LARGE}
\vspace{1.5cm}

Cheminformatics is the science of chemical data and computation.
The origin of the data is the wet lab, making collaboration an
intrinsic part of cheminformatics. However, as the field matured
it become more specialized, and with more specialization the
nature of those collaborations changed: collaboration could
have started as a lab scientist doing cheminformatics on the
side, after which it evolved to people specializing in
cheminformatics while collaborating with other scientists
in the same group, and later in other groups. Nowadays,
it is no longer uncommon to collaborate with scientists around
the world, as even the same university may no longer share
the same specialism. This is the era of online science.

Fortunately, cheminformatics is at an advantage compared to
other sciences, as the data exchange, processing, and analysis
is all done electronically anyway, making it suitable to be
scaled up to science online. This chapter will detail the
various tools cheminformaticians have at hand to simplify
this online collaboration.

Cheminformatics deals with the aggregation, handling, processing, and
analysis of chemical data. The nature of the chemical data is in principle
not important, but the history of the field and its separation from
quantum chemistry fields, bias the field towards small organic molecules.
The patterns in collaborative applications are, however, independent from
the exact nature of the data. Therefore, we will focus in this chapter
on another dimension to discuss the aspects of collaborative
cheminformatics applications: code development, knowledge handling
and data exchange, and collaborative computation.

The first section will focus on methods involved in the collaborative
development of cheminformatics software, and discuss the tools modern
scientists have to perform this task. The next section will describe
recent changes in which we handle chemical data and knowledge, and
in particular how the Internet is changing how communities crate new
knowledge bases. The third section will focus on the aspects of
collaborative computing in cheminformatics.

A fourth section describes social aspects of collaborative projects,
and in particular how collaboration is managed in projects with
only loosely defined roles of the various partners.

\section{Collaborative Code Development}

Collaborative code development is a common approach for large software vendors.
For scientific software, however, it is more uncommon: new software is typically
started as a PhD or M.Sc. project, with a single developer. There are, though,
two areas where collaborative code development in cheminformatics flourishes:
one situation is where a piece of software has become large and successful,
and multiple people have interest in contributing to the project; the second
situation is where the project is fairly small, and no single developer can
or wants to lead the project, as the topic is not core business.

An example of the latter situation is the JChemPaint project. There are existing
similar projects, making continued development out of scope of cheminformatics
research. However, Steinbeck et al. showing in 1998 that a collaborative project
can lead to an eco system where such software can still be
developed~\cite{Krause2000}.

Central to collaborative code development is sharing source code. Particularly,
it is pipelining how patches are shared and applied. While some cheminformatics
projects still share source code as source distributions, the adoption of
source code repositories as the golden standard. There are various 
open source repository technologies around, including Concurrent Versions System (CVS),
Subversion (SVN), Mercurial, Bazaar, and Git. CVS is the oldest and mostly replaced
by the newer technologies. Subversion is still abundant, but increasingly
replaced by the last three technologies. The reason for this is that
those three are distributed technologies, allowing server redundancy.

Moreover, because of the distributed nature of Mercurial, Bazaar, and Git,
branching and merges of branches is often easier. However, the increased
functionality also introduces further complexity, which is particularly
the case for Git, causing an increased learning curve.

As these tools are Open Source, anyone is able to set up a local server, but
Open Source projects can take advantage of service providers that host
free and public code repositories. Table~\ref{tab:cvsProviders}
provides an overview of various larger service providers, but there
are many alternatives.

\begin{table}
\caption{Overview of code sharing technologies and service providers
that provide free online hosting.}
\label{tab:cvsProviders}
\begin{center}
\begin{tabularx}{0.7\textwidth}{ll}
\toprule
\textbf{Technology} & \textbf{Provider(s)} \\
\midrule 
 Subversion & SourceForge~\cite{url:sourceforge}, Google Code~\cite{url:googlecode} \\ 
 Mercurial & Google Code \\ 
 Bazaar & LaunchPad~\cite{url:launchpad} \\ 
 Git & GitHub~\cite{url:github}, Gitorious~\cite{url:gitorious}, SourceForge \\ 
\bottomrule
\end{tabularx}
\end{center}
\end{table}

\subsection{Licensing}

Another aspect that makes collaboration easier, is to use an
Open Source license. Such a license ensures that potential
contributors know that whatever work they invest in the source
code is not lost: it will always be available to that
contributor under those license terms.
There are various Open Source licenses available, with
different characteristics. A discussion on differences and
details is well beyond the scope of this chapter, however.
They reader is kindly invited to read the book
Open Source Licensing by Lawrence Rosen~\cite{Rosen2004}.
Popular Open Source licenses include the GPL
licenses, and the MIT and BSD licenses. A full overview of Open
Source licenses is available from the Open Source Initiative:
\url{http://www.opensource.org/licenses}.

\subsection{Communication}

While sharing the source code is the primary channel of collaborative
code development, communication is a closed second. Designs
need to be discussed, solutions proposed. Traditionally,
mailing lists are popular ways of communication. A mailing
list is a "collection of names and addresses used by an individual
or an organization to send material to multiple recipients"~\cite{wp:mailinglist}
and simplifies sending an email to a particular development or
user community: by sending an email to the mailing list address
it is automatically distributed the all participants.

One interesting aspect is that increasingly this communication
is becoming more open and no longer limited to one project as
it often the case for mailing lists. Many Open Source developers
have started using blogs, where they discuss algorithms, theories,
etc. Among those blogs are those of two of the authors of this
chapter (see \url{http://blog.rguha.net/} and
\url{http://chem-bla-ics.blogspot.com/}),
but other blogs include the excellent that of
Gilleain Torrance (\url{http://gilleain.blogspot.com/}),
Noel O'Boyle (\url{http://baoilleach.blogspot.com/}), and
Tim VanderMeersch (\url{http://timvdm.blogspot.com/}).

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/cb.png}
\end{center}
\caption{The Cheminformatics section of Chemical blogspace
aggregates blog posts from cheminformaticians, providing
a platform for discussion of algorithms, theory, within
a larger community than that of a single project.}
\label{fig:cb}
\end{figure}

Blog planets and aggregators play an important role here.
Various cheminformatics projects have blog planets, where
the blogs from developers and users from the community
around that project are aggregated. For example, the
Chemistry Development Kit and Bioclipse have planets
at respectively \url{http://pele.farmbio.uu.se/planetcdk/} and
\url{planet.bioclipse.net}.
Aggregators also aggregate blogs, but not necessarily around
a specific developer or user community. One such website
that aggregates cheminformatics blogs is Chemical blogspace
(see Figure~\ref{fig:cb}).

A similar role have Question \& Answer websites, a new
type of communication channel popularized by StackOverflow
(\url{http://stackoverflow.com/}). This communication
concept is used, for example, by a the Blue Obelisk
eXchange at \url{http://blueobelisk.shapado.com/}
(see Figure~\ref{fig:shapado}) where
people can ask question on how to use a particular
cheminformatics library, or how to solve a particular
problem.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/boShapado.png}
\end{center}
\caption{The Blue Obelisk eXchange Question \& Answer
website is a open platform where people can ask on how
to use cheminformatics software, or ask for solutions
to a problem they have.}
\label{fig:shapado}
\end{figure}

\subsection{Peer review}

Another aspect of collaborative development is that one can
take advantage of peer review. While the role of peer review
in scientific publishing is well recognized, it is hardly
applied to scientific programming. Nevertheless, the
advantages are clearly recognized, such as written up
in the famous writing \textit{The Cathedral and the Bazaar}~\cite{Raymond2001}:

\begin{quotation}
It's one thing to observe in the large that the bazaar style
greatly accelerates debugging and code evolution. It's
another to understand exactly how and why it does so at the
micro-level of day-to-day developer and tester behavior.
\end{quotation}

The section then details on why the Bazaar model, with many
people looking at the code actually works. Now, interestingly,
this is where it may not apply to cheminformatics, where
the number of potential people looking at the code is
relatively low. Moreover, developers from competing projects
may have additional reasons not to review work from other
projects, further reducing the number of reviewers.

It should be noted that this problem is general to science,
and that peer review of publications too typically requires
a more formal approach. Code development has the advantage
that static source code checkers are available that can
detect common problems, such as PMD (\url{http://pmd.sf.net/}).
These tools check, for example, for unused variables, dead
code, etc, often highlighting sources of problems.

Manual peer code review is increasingly simplified by new
tools. For example, GitHub provides the functionality to
comment on changes~\cite{Chemblaics201005CodeReview},
increasing the communication between developers and the
social pressure to write better source code.
Figure~\ref{fig:githubCodereview} show an example comment
made via the GitHub website.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/codeReview8.png}
\end{center}
\caption{Screenshot of the GitHub webpage providing code
review functionality. The comments shows a reviewer question
regarding a parameter description missing in the JavaDoc
(see \url{http://github.com/egonw/bioclipse.cheminformatics/commit/3ce78ba}).}
\label{fig:githubCodereview}
\end{figure}


\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/kalzium.png}
\end{center}
\caption{Screenshot of the Kalzium, part of the KDE Software
Compilation (\url{http://kde.org/}), showing information on the
isotopes of cobalt using the Blue Obelisk Data Repository.}
\label{fig:kalzium}
\end{figure}

\section{Collaborative Knowledge Bases}

Cheminformatics is, of course, very much about information. This
information is embedded in knowledge bases, such as relational databases.
The knowledge in these information resources is derived from experimental
data. For example, force fields, which are used to calculate energies
for molecular conformations, are based on common patters, such as
average bond lengths, angles between two bonds that have one
atom in common, etc.

The collaborative building of knowledge bases is now well-established,
with popular examples in chemistry including compound databases
like PubChem and ChemSpider where people can deposit chemical
structures.
Social sites to share Open Data include the
NMRShiftDB~\cite{Steinbeck2004} (GNU FDL license),
ChemPedia (\url{http://chempedia.org/substances}, CC0 license),
and the Blue Obelisk Data Repository is a collaborative project by a number
of cheminformatics tools~\cite{Guha2006}, including Kalzium (see Figure~\ref{fig:kalzium}),
the Chemistry Development Kit, and others.
However, it should be noted that these collaborative, Open Data
resources are small in size, and that the collaborating community
is not (yet) of critical mass.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/wikichemistry}
\end{center}
\caption{Homepage of the WikiProject Chemistry, organizing the
editing of chemical articles on Wikipedia.}
\label{fig:wikichem}
\end{figure}

Wikipedia, instead, has an active development community and
collaboration within the WikiProject Chemistry
(\url{http://en.wikipedia.org/wiki/Wikipedia:WikiProject_Chemistry}).
This project has many contributors and keeps track of the chemistry
related pages in Wikipedia and has frequent discussions on how
to improve the chemistry on these pages. Collaboration is organized
via a project wiki page that can be edited by all contributors
(see Figure~\ref{fig:wikichem}).

The toxicology community, at the same time, is also bootstrapping
a community effort to share knowledge around the OpenTox Open Standard~\cite{Hardy2010}.
OpenTox provides an interoperable standard for the support of predictive toxicology,
including data management, and the specification of algorithms, modeling, validation and
reporting. OpenTox takes advantage of other Open Standards for data representation,
interfaces, vocabularies and ontologies: functionality is provided as REST services,
and replies are provided in various formats, including Resource Description Framework,
the underlying technology of the Semantic Web.

\subsection{Data standardization and interoperability}

Sharing of information and data requires well developed standards and exchange formats.
An example in cheminformatics is the extensible Chemical Markup Language (CML) which
is an approach to manage primarily molecular data, which has been extended to also
comprise other entities, including reactions and spectra. Another example is HUPO-PSI
Molecular Interaction format for the representation of molecular interaction
data~\cite{Orchard:2010uq}. The advantage of standardized file formats is that
applications can share information without loss of data, and it is becoming
increasingly common that data must be deposited in public repositories in an
open exchange formats prior to publication in scientific journals.

The cheminformatics community is slowly moving towards a more classical
standardization of knowledge: the use of ontologies. Ontologies are a formal
representations that are used to define concepts and their relationships in a
specific domain. By explicitly defining what a term means, it defines how
it should be used. Likewise, knowledge expressed with terms defined in
ontologies is more precise as anyone can look up what the exact meaning is.

There are various levels of detail an ontology can have, and in its most
simple form, the ontology is a controlled vocabulary, such as the IUPAC
Gold Book (\url{http://goldbook.iupac.org/}), which specifies chemical terminology.
More detailed ontologies, as those used by the knowledge management community,
define terms in much more detail, identifying classes, hierarchy of classes
(for example used by the Gene Ontology~\cite{GO2008,GO2010}), and relations
between classes. For example, a chemical ontology can specify what a \textit{molecule}
is, and that it is subclass of \textit{chemical entities}, and that a molecule can have
a \textit{boiling point}, and that a boiling point is a \textit{physical property of a chemical
entity}. These are the kind facts expressed in domain ontologies.
Ontologies have been used in chemistry since at least the 80-ties~\cite{Gordon1983},
but have received renewed interest lately~\cite{Feldman2005,Dumontier2009,Sankar2010}, possible triggered by the
open eXtensible Markup Language (XML) and and Web Ontology Language (OWL)
standards.

Ongoing community efforts to define ontologies related to cheminformatics include
the OpenTox API mentioned earlier, the Blue Obelisk Descriptor Ontology, and the
Chemical Information Ontology, a cheminformatics-oriented ontology
(\url{http://code.google.com/p/semanticchemistry/}). Another ontology
recently introduced to simplify building knowledge bases, is
the open exchange format QSAR-ML~\cite{Spjuth:2010fk} which aims at representing data sets
for Quantitative Structure-Activity Relationships (QSAR) in an open and completely
reproducible way. In QSAR, chemical structures are described by numerical vectors
(descriptors), and QSAR-ML makes use of the Blue Obelisk Descriptor Ontology for
uniquely defining descriptors. Also included is support for multiple versioned
implementations of these descriptors, which could be available on the local computer
or via remote Web services. QSAR-ML also comes with a reference implementation for
the Bioclipse~\cite{Spjuth2009,Spjuth2007} workbench, which provides a graphical
interface for setting up QSAR data sets. Prominent features include adding and
normalizing chemical structures in various formats, cherry-picking local and
remote descriptor implementations, adding responses and metadata, and finally
performing all calculations and exporting the complete data set in QSAR-ML.
Standardized QSAR opens up new ways to store, query, and exchange analysis,
and makes it is easy to join, extend, combine and also to work collectively with data.



\subsection{Linking Knowledge Bases}

Key to collaboration is also the sharing of knowledge. A prominent role here
plays the linking of various databases, which allows integration of them.

Resource Description Framework ... HCLS, Bio2RDF, Chem2Bio2RDF, ...

Userscripts present an approach to linking resources with a very low
barrier to entry. The idea of a userscript was first made available by
the Greasemonkey Mozilla extension and later by Ubiquity Mozilla
extension. A userscript was simply a small JavaScript program that
runs on the client browser and can modify a given web page before it
is displayed to the viewer. In other words, given permission to do so,
a userscript can completely rewrite a webpage in any way it sees
fit. This opens up exciting possibilities in annotating web content
and linking web content to arbitrary data sources. A variety of
userscripts for cheminformatics have been described by Willighagen et
al~\cite{Willighagen2007b}. For example, when viewing a web page describing
chemistry, a userscript can be written to take the text and run it
through a chemical entity recognition tool (such as OSCAR [REF]) and
then highlight terms that were recognized. Such a script can be further
enhanced by not only highlighting recognized terms, but inserting
hyperlinks to chemical databases such as PubChem or
ChemSpider. Another application described by Willighagen et al, was to
display 3D structures of molecules when browsing PubChem web pages. In
the past, PubChem did not provide 3D structure information. On the
other hand, Indiana University had generated a single low energy
conformer for 99\% of PubChem and stored them in a database. A
userscript was implemented that when run on a PubChem compound page,
would identify the compound ID and retrieve the corresponding 3D
structure (if available) from the Indiana University database and then
display it in a Jmol window. Key to the functionality of many
cheminformatics userscripts is the use of freely accessible
cheminformatics web services (Section \ref{ref:ws}) and databases.

\section{Collaborative Computing}

The development of infrastructure and tools to link knowledge bases is
a fundamental requirement for efficient collaborations. The previous
sections have highlighted a variety of efforts in these areas. While
it is true that collaborative efforts (in any field) are primarily a
function of social interactions, it is important to remember that
collaborations need not be directly between individuals. Rather, they
can also be mediated by software. From this point of view, there have
been a number of developments in the last few years that allow
individuals, unrelated to each other in terms of formal collaborative
agreements, to interact with each others' resources. But such
interactions do not necessarily have to involve remote
resources. Instead, a collaboration could also be in the form of
shared specifications.That is, individuals could collaborate on the
specification of a process or program, which would then be run locally
using each collaborators own resources. Finally, to achieve these
types of collaborative efforts, technologies to support these are
necessary; many of these are well established such as mailing lists
and chat systems, whereas a number are more recent such as service
registries. The following subsections discuss these facets of
collaborative computing in more detail.

\subsection{Shared Computing Services}
\label{ref:ws}

Distributed computing has gone through many phases starting with
Remote Procedure Calls (RPC) in the 1970a and 1980s to CORBA in the
1990s. More recently, distributed computing in the form of web
services have become a mechanism by which different groups expose both
methods (analogous to remote function calls that are the hallmark of
RPC and CORBA) as well as data. In this sense, we consider web
services to be a generalization, allowing one to provide access both
data (such as databases) and algorithms.

There are many protocols by which web services such as SOAP, REST, and
XMPP~\cite{Wagener2009}. Most web service protocols are designed to
work with multiple types of transport layers (HTTP, UDP, etc) but the
majority of web service protocols currently in use work over
HTTP. This approach results in significantly easier deploy of services
and access to them, since HTTP is ubiquitous throughout the
Internet. For a more detailed review of web service technologies the
reader is referred to XXX and YYY.

In this section we provide a brief overview of cheminformatics web
services and some use cases highlighting the collaborative potential
of such web services.

Indiana University has developed a number of cheminformatics web
services [REF] that provide access to core cheminformatics methods
(fingerprints, 2D depiction and various molecular descriptors),
statistical techniques (using R [REF] as the backend) and chemical
database access methods. Most of these services are implemented in
Java using the Chemistry Development Kit~\cite{Steinbeck2003} and SOAP as the
underlying protocol. A detailed description of these services can be
found in Dong et al~\cite{Dong2007Web}. The services have been used in
a variety of scenarios. For example, the fingerprint and statistical
model services were employed by Indiana University to develop
models to predict the activity of user supplied compounds against the
NCI60 cancer cell lines. Interestingly, the final predictive model was
itself, converted to a web service and thus accessible by any SOAP client,
remote or local. Note that while the model service was also located at
Indiana University, it could easily make use of fingerprint services
located at other sites, anywhere across the world.

Recently, these web services have been forked and reimplemented as
REST based services. While SOAP services can be ``hidden'' behind a
REST interface, the reimplementation avoids the extra complexity
imposed by SOAP, by directly exposing the functionality via the REST
interface. These services can be found at
\url{http://rguha.net/rest}. Currently, the
services are hosted at multiple locations include Drexel University,
USA and Uppsala University, Sweden and are utilized by a number of
independent applications. An example is the use of these services to
enhance an Open Notebook Science (ONS) project. The ONS Solubility
Challenge is an ongoing project in which a number of research groups
have experimentally determined the solubility of a variety of solutes
in a variety of solvents. All the data generated as part of this
project is publicly hosted on a GoogleDocs spreadsheet and outsiders
are encouraged to explore and mine the data, with the hope that their
results will be also be made Open. At the time of writing the project
has seen contributions from a number of people, including chemists,
mathematicians and programmers. As the project has grown, the number
of measurements now numbers in the hundreds. The spreadsheet contains
alphanumeric identifiers for solutes and solvents along with SMILES
representations and solubility data. In a number of cases, external
references are also included. While the use of Google Spreadsheets is
a very simple way to share data, the nature of the data makes it
unwieldy to explore. In general, while numeric solubility data is
useful it is more appropriate to explore it from a chemical point of
view - that is, in terms of structures and substructures.

As a result, a simple web page interface
(\url{http://toposome.chemistry.drexel.edu/~rguha/jcsol/sol.html})
was developed that extract data from the Google spreadsheet via the
Google-provided Data API and presented the data or filtered subsets of
the data (based on solute or solvent identifiers, substructures or
solubility ranges). The key feature of this application is the
incorporation of chemical intelligence, by making use of
cheminformatics web services hosted at Uppsala University. By making
use of these services, the SMILES strings stored in the spreadsheet
could be filtered by the presence or absence of substructures
(specified via SMARTS). In addition, the services were also employed
to provide 2D structure depictions of the results matching satisfying
the query. From a collaborative point of view, this application is
interesting as the developer had no role in the gathering of the
solubility data and did not create the online spreadsheet. Instead,
the application made use of public data API's provided by Google and
public web services hosted at another, remote location to extract and
present data that satisfied the requirements of another, external
group (i.e., the experimentalists making the measurements).

A related application (\url{http://old.oru.edu/cccda/sl/descriptorspace/ds.php}) 
was developed by another researcher to
explore the chemical space (via descriptor calculations followed by
principal components analysis). This application also made use of the
cheminformatics services hosted at Drexel University as well as
visualization services provided by Google, allowing users to generate
principal component plots of the solubility data, thereby
understanding the extent of the chemical space occupied by the current
set of chemical.

These applications highlight the fact that distributed software
resources were key in allowing multiple, unrelated parties to
collaborate on a publicly available data set. While this type of
collaboration could certainly be achieved using traditional software
resources (i.e., locally installed libraries and programs), the
presence of freely accessible web services (for both cheminformatics
as well as data and visualization) allows \emph{arbitrary} individuals
or groups to develop novel applications that were not considered by
the original researchers. Furthermore, the free and distributed nature
of the resources allows such developers free themselves of software
installation and management and onerous licensing conditions.


\subsection{Sharing Computation Specifications}

A simple example of a ``computation specification'' is the source code
of a program or even and input file for a program. In both cases, the
document fully specifies what is required to run a program to achieve
a desired result. Clearly there have been many mechanisms to share
such specifications. However, with a few exceptions these sharing
mechanisms tend to simply collect source code, for example, in a
central repository and let users access it from there. Usually, there
is no meta data attached or associated with the source code and thus
exploring related cases is difficult.

Recently, there has been significant amounts of efforts devoted to the
development of ``workflow'' or ``pipeline'' tools for chem- and
bioinformatics. These tools encapsulate core cheminformatics tasks
such as reading in SMILES, evaluating descriptors and so on in simple
graphical elements (usually boxes and connectors). A user can then
arrange sequences of such elements to perform a task. The GUI approach
coupled with the fact that in most cases, such workflow tools require
no programming knowledge make such tools very attractive to
experimentalists and other users with limited programming
experience. A number of such tools are available including Pipeline
Pilot, KNIME and Taverna~\cite{Oinn2004}.

A recent development around workflow tools is the sharing of workflow
specifications (or ``programs''), exemplified by the MyExperiment
website~\cite{Goble2010} which allows sharing of scientific workflow
of various formats, including Taverna (see Figure~\ref{fig:myexperiment})
and Bioclipse~\cite{Spjuth2009,Spjuth2007}.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/myexperiment.png}
\end{center}
\caption{Screenshot of the MyExperiment.org web page for a
Taverna workflow (\url{http://www.myexperiment.org/workflows/389.html}).}
\label{fig:myexperiment}
\end{figure}


\section{Managing Collaborative Projects}

We have provided a brief overview of various technologies that enable
and enhance collaborative projects in the field of
cheminformatics. Yet, one aspect still remains. While tools are
available to share source code and experimental data, how are such
collaborative projects managed? When the collaboration is between two
individuals, project management is not a significant problem. It
becomes much more problematic when the number of collaborators grows
larger.

The first aspect is communication between members of the
collaboration. A number of mechanisms are available including mailing
lists and online messaging systems. Both these methods have a long
history and mailing lists are a useful way to broadcast messages to
all members of a group. This has its downside as well, as many members
may not desire such broadcasted messages. Furthermore, email is
relatively inefficient at handling multiple conversations, though
threading [REF] does alleviate this. Modern email systems such as
Google Mail have provided a number of enhancements to improve the
handling of multiple conversations in a mailing list. 

One important aspect of mailing lists is that they are not real time
or interactive. On the other hand, messaging systems such as Internet
Relay Chat (IRC) or instant messengers (Yahoo Chat, AOL, etc.) offer
real time interactivity between participants. These systems allow for
direct interactions between multiple members and are extremely useful
for on-the-fly problem solving and discussions. Of course, since these
technologies are text based, it can be slower than phone or video
conferencing. But on the other hand, these systems are very light on
resources and efficient on slow Internet connections.

More recently, weblogs or blogs, have become a useful mode of
communication. This approach allows a degree of interactivity between
the producer of the blog and readers, but is primarily a vehicle for
an individual or group to provide updates. Of course, by allowing
multiple people to post on the blog, it can be a useful way for a
collaborative group to provide updates and information on the
project. Blogs are also useful from the consumers point of view since
they are a \emph{pull} technology. That is, the consumer (i.e.,
reader) will usually read the blog via an RSS reader and thus rather
than receive updates from the blog, will read new posts when desired.

The technologies discussed so far have focused on communication
between members of a collaboration and other interested parties. But
another vital aspect of collaborative projects is the development of
documentation - ranging from API documentation to tutorials and policy
documents. While one could exchange documents via email, one very
quickly runs into the problem of keeping everybody's edits
synchronized. Collaborative document editing systems have recently
been developed that directly address this problem. One example is
Google Docs, which is an online resource that allows one to create
documents, spreadsheets and presentations and then share them between
other users. Each authorized user can edit the document and more
importantly, multiple users can simultaneously work on these
documents. The service automatically tracks the edits by each users and
provides an intuitive view of the document history, allowing one to
view the edits made by each user. The documents can be exported to a
variety of common formats, allowing one to introduce such documents
into the traditional workflow.

Google Docs is a useful solution to the problem of collaborative
editing of traditional documents. Wikis provide another approach, that
is more free-form. The fundamental idea of a wiki is that it is a
collection of pages, linked via hyperlinks and that authorized users
can edit, add to or delete these pages arbitrarily. Most wikis will
also keep a history of the edits made to each page, allowing one to
track who did what. In contrast to something like Google Docs, wikis
are much more free form (indeed, they are fundamentally just web
pages). In addition, it is possible to add arbitrary files to a wiki,
which allows one to record and track the entire state of a project
over time (cf. the Open Notebook Science Solubility Challenge on
Wikispaces [URL]). While wikis are useful they are not necessarily the
best solution for all cases. For example, in software development
projects, keeping an associated wiki up to date with the state of the
project can be tedious, especially if the development is very
rapid. While the wiki might be useful for material such as tutorials
and so on, it is rarely a good solution for API documentation. Many
would argue that even usage information should be a part of the API
documentation and should be written inline with the code. Such inline
documentation can easily be extracted and formatted using tools such
as Doxygen or Sphinx and \emph{linked to} from the wiki. This last
point highlights one advantage of a wiki type of system - it is a very
easy way to aggregate resources via linking rather than include them
directly in the wiki itself. This leads to significantly lower efforts
in maintaining the wiki.

In addition to these systems, tools that have traditionally been
focused on software development can be usefully applied to other
scenarios. A good example is the use of a bug tracking systems to keep
track of feature requests or new ideas. These systems allow one to
keep a list of these issues and possibly assign them to one or more
people for followup.

It should be noted that the software systems to support the ideas
described here can be obtained in a variety of forms. Each component
described here can be obtained individually, require the collaboration
to set them up whereas more comprehensive solutions also exist that
couple wikis, feature tracking systems and collaborative editing
systems in a single package. In addition, one has a choice of Open
Source or commercial solutions to choose from.

We have discussed a variety of technologies that facilitate
collaborative project management. But a vital component of this is the
management of people within such projects. There are many approaches to
this ranging from committees to dictatorships (benevolent or
otherwise). In this chapter we do not discuss the merits or demerits
of any given approach, save to say that efficient personnel management
is vital to the successful completion of a collaborative project.

\section{Conclusion}

In this chapter we have discussed the various aspects of collaborative
cheminformatics. We outlined tools available for software development,
building knowledge bases, and tools for collaborative computing.
We also outlined the roles Open Source, Open Data, and Open Standards
have in building successful collaborations, such as the roles of
licensing as social contract between collaborators, and communication
channels to discuss ideas. Similarly, we shows how Open Standards
make it easier to build collaborative knowledge bases as they
provide a unified, clear-to-all interface to the data. We further
described how collaborative computing can be set up and how
scientists can share high-level workflow specifications.

\bibliographystyle{unsrt}
\bibliography{chapter}

\end{document}


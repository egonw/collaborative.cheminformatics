\documentclass[11pt]{book}

\newcommand{\refname}{}
\newcommand{\ola}[1]{{\color{green} OLA: #1}}
\newcommand{\rg}[1]{{\color{red} RG: #1}}

\usepackage[utf8]{inputenc}
%\usepackage{a4wide}
\usepackage{bibspacing}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{times}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{ctable}


\begin{document}

\chapter{Collaborative Cheminformatics Applications}

\begin{LARGE}
Rajarshi Guha, Ola Spjuth, Egon Willighagen
\end{LARGE}
\vspace{1.5cm}

Cheminformatics is the science of chemical data and computation.  The
origin of the data is generally from the wet lab,
thereby making collaboration an intrinsic part of cheminformatics:
data aggregation, preprocessing, and review involves many other
scientists. Moreover, as most cheminformatics approaches find
patterns and relationsips at various levels of detail, using
methodologies are typically mathematical and are
aimed at identifying correlations, not physical and chemical
cause-effect relations, the domain finds itself once
again collaborating with the experimental scientist to validate
the derived models and predictions against new experimental data.

However, as the field has matured it has become more specialized,
and with more specialization, the nature of those collaborations
have changed: a study could have started as a lab scientist doing
cheminformatics as a side project, while the domain later evolved to people
specializing in cheminformatics while collaborating with other
scientists in the same group, and later collaborating with other
resarch groups. Nowadays, it is even ccommon to collaborate with
scientists around the world as even the same university may no
longer share the same speciality. Evolution of internet technologies
resulted in an era of online science.

Fortunately, cheminformatics is at an advantage compared to
other sciences. Data exchange, processing, and analysis
is all done electronically, making it suitable to be
scaled up to science online. This chapter will define and detail the
various tools cheminformaticians have at hand to simplify
this online collaboration.

Cheminformatics deals with the aggregation, handling, processing, and
analysis of chemical data. The nature of the chemical data is in principle
not important. However, the history of the field and its separation from
quantum chemistry fields, bias the domain towards small organic molecules.
The patterns in collaborative applications are, however, independent of
the exact nature of the data. Therefore, we will focus in this chapter
on another dimension to discuss the aspects of collaborative
cheminformatics applications: code development, knowledge handling
and data exchange, and collaborative computation.

The first section will focus on methods involved in the collaborative
development of cheminformatics software, and will discuss the tools modern
scientists have to perform this task. The next section will describe
recent changes in which we handle chemical data and knowledge, and in
particular how the internet is changing the way communities create new
knowledge bases. The third section will focus on the aspects of
collaborative computing in cheminformatics. Finally, the fourth
section will describe social aspects of collaborative projects, and in
particular how collaboration is managed in projects with only loosely
defined roles for the various partners.

\section{Collaborative Code Development}

Collaborative code development is a common approach for large software vendors.
For scientific software, however, it is less common: new software is typically
started as a PhD or M.Sc. project, with a single developer. There are, however,
two areas where collaborative code development in cheminformatics flourishes:
one situation is where a piece of software has become large and successful,
and multiple people have interest in contributing to the project; the second
situation is where the project is fairly small, and no single developer can
or wants to lead the project, as the topic is not core to their research.

An example of the latter situation is the JChemPaint project~\cite{Krause2000}.
There are existing similar projects, making continued development out
of the scope of cheminformatics
research. However, Steinbeck et al. showed in 1998 that a collaborative project
can lead to an ecosystem where such software can still be
developed.

Central to collaborative code development is the sharing of source code. Particularly,
it is the pipelining of how patches are shared and applied. While some cheminformatics
projects still share source code as source distributions, the adoption of
source code repositories has emerged as the golden standard. There are various 
open source repository technologies available, including the Concurrent Versions System
(CVS)~\cite{url:cvs}, Subversion (SVN)~\cite{url:svn}, Mercurial~\cite{url:hg},
Bazaar~\cite{url:bazaar}, and Git~\cite{url:git}. CVS is the oldest and mostly replaced
by the newer technologies. Subversion is still abundant, but increasingly
replaced by the last three technologies. The reason for this is that
the latter three system are distributed technologies, allowing for server redundancy.

Moreover, because of the distributed nature of Mercurial, Bazaar, and Git,
branching and merges of branches is often easier. However, the increased
functionality also introduces further complexity, which is particularly
the case for Git, and leads to a steeper learning curve.

As these tools are Open Source, anyone is able to set up a local,
possibly private server, but
Open Source projects can take advantage of service providers that host
free and public code repositories. Table~\ref{tab:cvsProviders}
provides an overview of various larger service providers, but there
are many alternatives.

\begin{table}
\caption{Overview of code sharing technologies and service providers
that provide free online hosting.}
\label{tab:cvsProviders}
\begin{center}
\begin{tabularx}{0.7\textwidth}{ll}
\toprule
\textbf{Technology} & \textbf{Provider(s)} \\
\midrule 
 Subversion & SourceForge~\cite{url:sourceforge}, Google Code~\cite{url:googlecode} \\ 
 Mercurial & Google Code \\ 
 Bazaar & LaunchPad~\cite{url:launchpad} \\ 
 Git & GitHub~\cite{url:github}, Gitorious~\cite{url:gitorious}, SourceForge \\ 
\bottomrule
\end{tabularx}
\end{center}
\end{table}

\subsection{Licensing}

A second aspect that simplifies collaboration is to use an
Open Source license. Such a license ensures that potential
contributors know that whatever work they invest in the source
code is not lost: it will always be available to that
contributor under those license terms.
There are various Open Source licenses available, with
different characteristics. A discussion on differences and
details is well beyond the scope of this chapter, however.
The reader is encouraged to read the book
Open Source Licensing by Lawrence Rosen~\cite{Rosen2004}
to gain additional information in this area.
Popular Open Source licenses include the GPL
licenses~\cite{url:license:lgpl,url:license:gpl}, and
the MIT~\cite{url:license:mit} and BSD licenses~\cite{url:license:bsd}. A full overview of Open
Source licenses is maintained by the Open Source Initiative~\cite{url:osi}.

\subsection{Peer review}

While sharing the source code is the primary channel of collaborative
code development, communication is a close second. Designs
need to be discussed, and solutions proposed. Peer review
is part of this, and plays an important part in collaborative
code development. A full discussion of communication
will be discussed later in this chapter as part of project
management, while here we will focus on peer review only.

While the role of peer review in scientific publishing is
well recognized as an important path for communication, it is rarely
applied to scientific programming. Nevertheless, the
advantages and disadvantages are clearly recognized for source
code development as well, as detailed in
in the famous article titled "The Cathedral and the Bazaar"~\cite{Raymond2001}:

\begin{quotation}
"It's one thing to observe in the large that the bazaar style
greatly accelerates debugging and code evolution. It's
another to understand exactly how and why it does so at the
micro-level of day-to-day developer and tester behavior."
\end{quotation}

The article continues to detail why the Bazaar model, with many
people looking at the code actually works. Interestingly,
this is where it may not directly apply to cheminformatics as
the number of potential people looking at the code is actually
relatively low. Moreover, developers from competing projects
may have additional reasons not to review the work from other
projects, further reducing the number of reviewers. 
It should be noted that this problem is general to science,
and that peer review of publications too typically requires
a more formal approach. Peer reviewed code development 
has the advantage
that static source code checkers are available that can
detect common problems, such as PMD~\cite{url:pmd}.
These tools check, for example, for unused variables, dead
code, etc, often highlighting sources of problems.

Manual peer code review is increasingly simplified by new
tools. For example, GitHub provides the functionality to
comment on changes~\cite{Chemblaics201005CodeReview},
increasing the communication between developers and the
social pressure to write better source code.
Figure~\ref{fig:githubCodereview} shows an example comment
made via the GitHub website.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/codeReview8.png}
\end{center}
\caption{A screenshot of the GitHub webpage providing code
review functionality. The comments shows a reviewer question
regarding a parameter description missing in the JavaDoc
(see \url{http://github.com/bioclipse/bioclipse.cheminformatics/commit/3ce78ba}).}
\label{fig:githubCodereview}
\end{figure}

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/kalzium.png}
\end{center}
\caption{A screenshot of the Kalzium, part of the KDE Software
Compilation, showing information on the
isotopes of cobalt using the Blue Obelisk Data Repository.}
\label{fig:kalzium}
\end{figure}

\section{Collaborative Knowledge Bases}

Cheminformatics is, of course, very much about information. This
information is embedded in knowledge bases, such as relational databases.
The knowledge in these information resources is derived from experimental
data. For example, force fields, which are used to calculate energies
for molecular conformations, are based on common patterns, such as
average bond lengths, the angles between two bonds that have one
atom in common, etc.

The collaborative building of knowledge bases is now well-established,
with popular examples in chemistry including compound databases
like PubChem~\cite{url:pubchem} and ChemSpider~\cite{url:chemspider}
where people can deposit chemical structures.
Social sites to share Open Data include the
NMRShiftDB~\cite{Steinbeck2004} (licensed under a GNU FDL license),
ChemPedia~\cite{chempedia} (available under a CC0 license),
and the Blue Obelisk Data Repository which is a collaborative project
initiated by a number
of cheminformatics tools~\cite{Guha2006}, including Kalzium~\cite{url:kalzium}
(see Figure~\ref{fig:kalzium}),
the Chemistry Development Kit, and others.
However, it should be noted that these collaborative, Open Data
resources are small in size, and that the collaborating community
is not, as yet, of critical mass.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/wikichemistry}
\end{center}
\caption{The homepage of the WikiProject Chemistry, organizing the
editing of chemical articles on Wikipedia.}
\label{fig:wikichem}
\end{figure}

In contrast, Wikipedia has an active development community and
collaboration within the WikiProject Chemistry~\cite{wikichem}.
This project has many contributors and keeps track of the chemistry
related pages in Wikipedia and has frequent discussions on how
to improve the chemistry on these pages. Collaboration is organized
via a project wiki page that can be edited by all contributors
(see Figure~\ref{fig:wikichem}).

The toxicology community has bootstrapped
a community effort to share knowledge around the OpenTox Open Standard~\cite{Hardy2010}.
OpenTox provides an interoperable standard for the support of predictive toxicology,
including data management, and the specification of algorithms, modeling, validation and
reporting. OpenTox takes advantage of other Open Standards for data representation,
interfaces, vocabularies and ontologies: functionality is provided as
RESTful services~\cite{fielding:2000},
and replies are provided in various formats, including the Resource Description
Framework~\cite{Carroll:04:RDF},
the underlying technology of the Semantic Web~\cite{BernersLee2001}.

\subsection{Data standardization and interoperability}

Sharing of information and data requires well developed standards and
exchange formats as discussed in Chapter 14.
An example in cheminformatics is the extensible Chemical Markup Language
(CML)~\cite{MurrayRust1999} which
is an approach to manage primarily molecular data, which has been extended to also
comprise other entities, including reactions and spectra. Another example is the HUPO-PSI
Molecular Interaction format for the representation of molecular interaction
data~\cite{Orchard:2010uq}. The advantage of standardized file formats is that
applications can share information without loss of data, and it is becoming
increasingly common that data must be deposited in public repositories in
open exchange formats prior to publication in scientific journals.

The cheminformatics community is slowly moving towards a more classical
standardization of knowledge: the use of ontologies. Ontologies are formal
representations that are used to define concepts and their relationships in a
specific domain. By explicitly defining what a term means, it defines how
it should be used. Likewise, knowledge expressed with terms defined in
ontologies is more precise as others can then look up what the exact meaning is.

There are various levels of detail in ontology and in its most
simple form, the ontology is a controlled vocabulary. An example is the IUPAC
Gold Book~\cite{url:goldbook}, which specifies chemical terminology.
More detailed ontologies, such as those used by the knowledge management community,
define terms in much more detail, identifying classes, the hierarchy of classes
(for example used by the Gene Ontology~\cite{GO2008,GO2010}), and relationships
between classes. For example, a chemical ontology can specify what a \textit{molecule}
is, and that it is a subclass of \textit{chemical entities}, and that a molecule can have
a \textit{boiling point}, and that a boiling point is a \textit{physical property of
a chemical entity}. These are representative of the type of facts
that are expressed in domain ontologies.
Ontologies have been used in chemistry since at least the 1980s~\cite{Gordon1983},
but have received renewed interest lately~\cite{Feldman2005,Dumontier2009,Sankar2010},
possibly triggered by the open eXtensible Markup Language (XML)~\cite{Bray:08:EML}
and the Web Ontology Language (OWL) standards~\cite{Group:09:OWO}.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/qsar-collab.png}
\end{center}
\caption{A screenshot showing the creation of a QSAR data set in Bioclipse,
where a set of molecules is aggregated and molecular descriptors are
selected, creating a numerical representation suitable for statistical
modeling.}
\label{fig:qsarml}
\end{figure}

Ongoing community efforts to define ontologies related to cheminformatics include
the OpenTox API mentioned earlier, the Blue Obelisk Descriptor Ontology, and the
Chemical Information Ontology, a cheminformatics-oriented ontology~\cite{url:cheminf}. 
Another ontology recently introduced to simplify building knowledge bases, is
the open exchange format QSAR-ML~\cite{Spjuth:2010fk} which aims at representing data sets
for Quantitative Structure-Activity Relationships (QSAR) in an open and completely
reproducible way. In QSAR, chemical structures are described by numerical vectors
(known as descriptors), and QSAR-ML makes use of the Blue Obelisk Descriptor Ontology for
uniquely defining these descriptors. Also included is support for multiple, alternative
implementations of these descriptors, which could be available on the local computer
or via remote Web services. QSAR-ML also comes with a reference implementation for
the Bioclipse workbench~\cite{Spjuth2009,Spjuth2007}, which provides a graphical
interface for setting up QSAR data sets, as shown in Figure~\ref{fig:qsarml}.
Prominent features include adding and
normalizing chemical structures in various formats, cherry-picking local and
remote descriptor implementations, adding responses and metadata, and finally
performing all calculations and exporting the complete data set in QSAR-ML.
Standardized QSAR opens up new ways to store, query, and exchange analysis,
and makes it easy to join, extend, combine and to work collectively with data.



\subsection{Linking Knowledge Bases}

One of the keys to collaboration is also the sharing of knowledge.
A prominent role here is in the linking of various databases,
thereby allowing their integration and, where appropriate, their federation.
Traditionally, linking databases is done by using shared identifiers.
Well-known identifiers for chemical structures include
database-specific identifiers, such as the CAS registry number~\cite{url:casnumber},
the PubChem Compound Identifier~\cite{url:pubchemcid},
and the ChemSpider Identifier~\cite{url:chemspider}.
When these are shared, they can be used to connect databases.
Alternatively, one could use an identifier which can be calculated
from the object itself. For a wide set of small, organic molecules
the InChI~\cite{Stein2003} fulfills this role~\cite{Coles2005}.

An interesting proposal was made with the Resource Description
Framework~\cite{Carroll:04:RDF} which suggests that a Universal
Resource Identifier (URI)~\cite{rfc3986} is used to identify
information in a database. Common URIs include web addresses,
such as \url{http://www.chemspider.com/}.
The URI specification is an open
standard that formalizes the structure of identifiers:
an identifier consists of a scheme (\textit{http}),
followed by a ':', and then an authority prefixed with
"//" (\textit{//www.pharmbio.org}) and
finally a path ('/'). An example of a URI that does not contain an authority,
is the URI used in web pages to link to an email address, such as
\href{mailto:bioclipse-devel@lists.sourceforge.net}, where the
scheme is \textit{mailto}, and the path is the email address.
Other URIs include the Life Science Identifier (LSID)~\cite{Clark2004}.
For example, The LSID for the 1AFT protein in the
PDB database is \textit{urn:lsid:pdb.org:pdb:1aft}. The \textit{urn}
scheme in the LSID refers to the Uniform Resource Names (URNs)
specification which is based on the URI, but aimed at being
location independent~\cite{rfc2141}.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.6\textwidth]{graphics/ons.pdf}
\end{center}
\caption{The rdf.openmolecules.net website operates as a hub
in the Semantic Web for small molecules by using the InChI
to create unique molecular URIs to provide a dereferenceable
RDF resource for any compound.}
\label{fig:ons}
\end{figure}

Using these URIs it is possible to create a Linked Open Data
network, linking together different databases on the
Semantic Web. A subsection of this linked data network
is created by the website \url{http://rdf.openmolecules.net/}
which takes advantage of the InChI to create a network for
small molecules. Figure~\ref{fig:ons} shows how this is used
to create links to ChEBI~\cite{Degtyarenko2008}, ChemSpider,
NMRShiftDB~\cite{Steinbeck2003b} and other
resources~\cite{Willighagen2010jbiomedsem}. By taking
advantage of such identifiers, the various participants
can easily collaborate but work quite independently at the
same time. Other large initiatives in this area include
the Semantic Web for Health Care and Life Sciences Interest Group of the
World Wide Web consortium~\cite{hclsig},
Bio2RDF~\cite{Belleau2008} and Chem2Bio2RDF~\cite{Chen2010}.

Userscripts also present an approach to linking resources with a very low
barrier to entry. The idea of a userscript was first made available by
the Greasemonkey Mozilla extension~\cite{url:greasemonkey} and
later by the Ubiquity Mozilla extension~\cite{url:ubiquity}.
A userscript is simply small JavaScript program that
runs on the client browser and can modify a given web page before it
is displayed to the viewer. In other words, given permission to do so,
a userscript can completely rewrite a web page in any way
deemed appropriate and necessary to the task at hand.
This opens up exciting possibilities in annotating web content
and linking web content to arbitrary data sources. A variety of
userscripts for cheminformatics have been described by Willighagen et
al~\cite{Willighagen2007b}. For example, when viewing a web page describing
chemistry, a userscript can be written to take the text and run it
through a chemical entity recognition tool (such as OSCAR3~\cite{Corbett2006}) and
then highlight terms that were recognized. Such a script can be further
enhanced by not only highlighting recognized terms, but inserting
hyperlinks to chemical databases such as PubChem or
ChemSpider. Another userscript application described, is to
display the 3D structures of molecules when browsing PubChem web pages.
Previously, PubChem had not provided 3D structure information, while
Indiana University had separately generated a single low energy
conformer for 99\% of PubChem and stored them in an independent database. A
userscript was implemented that when run on a PubChem compound page,
would identify the compound ID and retrieve the corresponding 3D
structure (if available) from the Indiana University database and then
display it in a Jmol window. Key to the functionality of many
cheminformatics userscripts is the use of freely accessible
cheminformatics web services (Section~\ref{ref:ws}) and databases.

\section{Collaborative Computing}

The development of the necessary infrastructure and tools to link knowledge bases is
a fundamental requirement for efficient collaborations. The previous
sections have highlighted a variety of efforts in these areas. While
it is true that collaborative efforts (in any field) are primarily a
function of social interactions, it is important to remember that
collaborations need not be directly between individuals. Rather, they
can also be mediated by software. From this point of view, there have
been a number of developments in the last few years that allow
individuals, unrelated to each other in terms of formal collaborative
agreements, to interact with each others' resources. But such
interactions do not necessarily have to involve remote
resources. Instead, a collaboration could also be in the form of
shared specifications.That is, individuals could collaborate on the
specification of a process or program, which would then be run locally
using each collaborators own resources. Finally, to achieve these
types of collaborative efforts, technologies to support these are
necessary. Many of these are well established including mailing lists
and chat systems, whereas a number are more recent and include service
registries. The following subsections discuss these facets of
collaborative computing in more detail.

\subsection{Shared Computing Services}
\label{ref:ws}

Distributed computing has gone through many phases starting with
Remote Procedure Calls (RPC)~\cite{rfc707} in the 1970s-80s to
CORBA~\cite{url:corba1.0} in the
1990s. More recently, distributed computing in the form of so-called
web services have emerged. Because these services expose methods,
like RPC and CORBA, but also data, we consider web
services to be a generalization, allowing one to provide access to
both data (contained in databases) as well as algorithms.

There are many protocols on which web services can be based.
These include SOAP~\cite{Gudgin:07:SVP},
REST~\cite{fielding:2000} and
XMPP~\cite{Wagener2009}. Most web service protocols are designed to
work with multiple types of transport layers (HTTP, UDP, etc) but the
majority of web service protocols currently in use work over
HTTP. This approach results in significantly easier deployment and
access of services since HTTP is ubiquitous across the
Internet. For a more detailed review of web service technologies the
reader is referred to Curcin et al\cite{Curcin:2005fk} and Fielding et
al\cite{Fielding:2002eu}.

In this section we provide a brief overview of cheminformatics web
services and some use cases highlighting the collaborative potential
of such web services.

Indiana University has developed a number of cheminformatics web
services~\cite{Dong2007Web} that provide access to core cheminformatics methods
(fingerprints, 2D depiction and various molecular descriptors),
statistical techniques (using R\cite{r} as the backend) and chemical
database access methods. Most of these services are implemented in
Java using the Chemistry Development Kit~\cite{Steinbeck2003} and SOAP as the
underlying protocol. The services have been used in
a variety of scenarios. For example, the fingerprint and statistical
model services were employed by Indiana University to develop
models to predict the activity of user supplied compounds against the
NCI60 cancer cell lines~\cite{Dong2007Web}. Interestingly, the final predictive model was
itself, converted to a web service and thus accessible by any SOAP client,
remote or local. Note that while the model service was also located at
Indiana University, it could easily make use of fingerprint services
located at other sites, anywhere across the world.

Recently, these web services have been forked and reimplemented as
REST based services. While SOAP services can be ``hidden'' behind a
REST interface, the reimplementation avoids the extra complexity
imposed by SOAP, by directly exposing the functionality via the REST
interface. These services can be found at
\url{http://rguha.net/rest}. Currently, the
services are hosted at multiple locations and include Drexel University,
USA and Uppsala University, Sweden, and are utilized by a number of
independent applications. An example is the use of these services to
enhance an Open Notebook Science (ONS) project~\cite{Bradley2009},
as reviewed elsewhere in this book. The ONS Solubility
Challenge is an ongoing project in which a number of research groups
have experimentally determined the solubility of a variety of solutes
in a variety of solvents. All the data generated as part of this
project is publicly hosted on a GoogleDocs spreadsheet and outsiders
are encouraged to explore and mine the data, with the hope that their
results also will be Open. At the time of writing the project
has seen contributions from a number of people, including chemists,
mathematicians and programmers. As the project has grown, the number
of measurements now numbers in the hundreds. The spreadsheet contains
alphanumeric identifiers for solutes and solvents along with SMILES
representations and solubility data. In a number of cases, external
references are also included. While the use of Google Spreadsheets is
a very simple way to share data, the nature of the data makes it
unwieldy to explore. In general, while numeric solubility data is
useful it is more appropriate to explore it from a chemical point of
view - that is, in terms of structures and substructures.

As a result, a simple web page interface was developed~\cite{url:onsgui}
that extract data from the Google spreadsheet via the
Google-provided Data API and presents views of the data or filtered subsets of
the data (based on solute or solvent identifiers, substructures or
solubility ranges). The key feature of this application is the
incorporation of chemical intelligence, by making use of
cheminformatics web services hosted at Uppsala University. By making
use of these services, the SMILES strings~\cite{Weininger1988} stored in the spreadsheet
could be filtered by the presence or absence of substructures
(specified via SMARTS~\cite{url:smarts}). In addition, the services were also employed
to provide 2D structure depictions of the results matching satisfying
the query. From a collaborative point of view, this application is
interesting as the developer had no role in the gathering of the
solubility data and did not create the online spreadsheet. Instead,
the application made use of public data APIs provided by Google and
public web services hosted at another, remote location to extract and
present data that satisfied the requirements of another, external
group (i.e., the experimentalists making the measurements).

A related application was developed by another researcher to
explore the chemical space via descriptor calculations followed by
principal components analysis~\cite{url:descriptorspace}.
This application also made use of the
cheminformatics services hosted at Drexel University as well as
visualization services provided by Google, allowing users to generate
principal component plots of the solubility data and thereby
understanding the extent of the chemical space occupied by the current
set of chemicals.

These applications highlight the fact that distributed software
resources were key in allowing multiple, unrelated parties to
collaborate on a publicly available data set. While this type of
collaboration could certainly be achieved using traditional software
resources (i.e., locally installed libraries and programs), the
presence of freely accessible web services (for both cheminformatics
as well as data and visualization) allows \emph{arbitrary} individuals
or groups to develop novel applications that were not considered by
the original researchers. Furthermore, the free and distributed nature
of the resources allows such developers free themselves of software
installation and management and onerous licensing conditions.


\subsection{Sharing Computation Specifications}

A simple example of a ``computation specification'' is the source code
of a program or even an input file for a program. In both cases, the
document fully specifies what is required to run a program to achieve
a desired result. Clearly there have been many mechanisms to share
such specifications. However, with a few exceptions these sharing
mechanisms tend to simply collect source code, for example, in a
central repository and let users access it from there. Usually, there
is no meta data attached or associated with the source code and thus
exploring related cases is difficult.

Recently, there has been a significant amounts of effort devoted to the
development of ``workflow'' or ``pipelining'' tools for chem- and
bioinformatics. These tools encapsulate core cheminformatics tasks
such as reading in SMILES, evaluating descriptors and so on in simple
graphical elements (usually boxes and connectors). A user can then
arrange sequences of such elements to perform a task. The GUI approach
coupled with the fact that in most cases, such workflow tools require
no programming knowledge make such tools very attractive to
experimentalists and other users with limited programming
experience. A number of such tools are available including Pipeline
Pilot~\cite{url:pipelinepilot}, KNIME~\cite{Berthold2009} and
Taverna~\cite{Oinn2004}.

A recent development around workflow tools is the sharing of workflow
specifications (or ``programs''), exemplified by the MyExperiment
website~\cite{Goble2010} which allows sharing of scientific workflow
of various formats, including Taverna~\cite{Oinn2004,Kuhn2010}
(see Figure~\ref{fig:myexperiment})
and Bioclipse~\cite{Spjuth2009,Spjuth2007}.
MyExperiment is a social website where scientists can share
workflow specifications, tag them, categorize them, or modify and
upload new, improved versions. This makes it easy to
reproduce analyses and potentially improve scientific progress.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/myexperiment.png}
\end{center}
\caption{A screenshot of the MyExperiment.org web page for a
CDK-Taverna workflow (\url{http://www.myexperiment.org/workflows/389.html}).}
\label{fig:myexperiment}
\end{figure}

\subsection{Online Cheminformatics Computation}

It should be noted that these online workflow sharing services do
require download of the workflows to a local desktop, where
they can then be run. Both Taverna and Bioclipse provide
the means to download a workflow shared on MyExperiment.org from
within the desktop software, but it is not possible
to run the computation at a remote server unless the workflow
specifies that.
However, the ongoing evolution of collaborative cheminformatics
is making this possible and various companies are appearing that
develop software that make
it possible to design and run workflows via websites.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/wingu.png}
\end{center}
\caption{A screenshot of Wingu Elements, an online scientific
computing platform with cheminformatics functionality.}
\label{fig:wingu}
\end{figure}

One example of this approach is Wingu Elements~\cite{wingu}, by the Boston start up
Wingu Inc. This product provides a cloud-based platform for research teams
to define workflows, make them available within the collaboration, and
then share the results as shown in Figure~\ref{fig:wingu}.

A second online collaborative cheminformatics platform is the
Inkspot Platform by Inkspot Science~\cite{inkspot}. On this platform
workflows can be designed, run, and shared (see
Figure~\ref{fig:inkspot}). An extra dimension
is given here by the company to provide hosting thereby allowing the creation
of small communities or research projects, much like open source
projects take advantage of hosting services like the aforementioned
SourceForge and GitHub.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/inkspot.png}
\end{center}
\caption{A screenshot of the Inkspot Platform for collaborative
cheminformatics analyses.}
\label{fig:inkspot}
\end{figure}


\section{Managing Collaborative Projects}

We have provided a brief overview of various technologies that enable
and enhance collaborative projects in the field of
cheminformatics. Yet, one aspect still remains open to discussion. While tools are
available to share source code and experimental data, how should such
collaborative projects be managed? When the collaboration is between two
individuals, project management is not a significant problem, but it
becomes much more problematic when the number of collaborators grows
larger.

The first aspect is communication between members within the
collaboration. A number of mechanisms are available including mailing
lists and online messaging systems. Both these methods have a long
history and mailing lists are a useful way to broadcast messages to
all members of a group~\cite{wp:mailinglist}:
by sending an email to the mailing list address
it is automatically distributed across all of the participants.
This has an associated downside as members
may not desire such broadcasted messages which may not be
relevant to them. Furthermore, email is
relatively inefficient at handling multiple conversations, though
threading does alleviate this. Modern email systems such as
Google Mail have provided a number of enhancements to improve the
handling of multiple conversations in a mailing list, such as
automatic filtering of messages to mailing lists directly into
a folder, instead of the main inbox.

One important aspect of mailing lists is that they are not real time
or interactive. On the other hand, messaging systems such as Internet
Relay Chat (IRC)~\cite{rfc1459} or instant messengers (Yahoo Chat, AOL, etc.) offer
real time interactivity between participants. These systems allow for
direct interactions between multiple members and are extremely useful
for immediate problem solving and discussions. Of course, since these
technologies are text based, it can be slower to communicate
problems than it would be using phone or video
conferencing. On the other hand, these systems are very light on
resources and quiet efficient on slow Internet connections. The use of
IRC is particularly prominent amongst Open Source projects. For
example, Bioclipse, OpenBabel~\cite{url:openbabel}, and CDK developers use, respectively,
the \#bioclipse, \#openbabel, and \#cdk channels on the
FreeNode.net network~\cite{url:freenode}. While it is common to use
dedicated IRC clients (see Wikipedia~\cite{wp:ircclients}),
these channels can also be accessed via a web interface at
\url{http://webchat.freenode.net/}.

More recently, weblogs or blogs, have become a useful mode of
communication. This approach allows a degree of interactivity between
the producer of the blog and readers, but is primarily a vehicle for
an individual or group to provide updates. Of course, by allowing
multiple people to post on the blog, it can be a useful way for a
collaborative group to provide updates and information on the
project. Blogs are also useful from the consumers point of view since
they are a \emph{pull} technology. That is, the consumer (i.e.,
reader) will usually read the blog via an RSS reader and thus rather
than receive updates from the blog, will read new posts when desired.

One interesting aspect is that increasingly this communication
is becoming more open and no longer limited to one project as
it often the case for mailing lists. Many Open Source developers
have started using blogs, where they discuss algorithms, theories,
etc. Among those blogs are those of two of the authors of this
chapter~\cite{blog:rguha,blog:egonw},
but other blogs include the excellent one of
Gilleain Torrance~\cite{blog:gilleain},
Noel O'Boyle~\cite{blog:noel}, and
Tim VanderMeersch~\cite{blog:tim}.

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.6\textwidth]{graphics/cb.png}
\end{center}
\caption{The Cheminformatics section of Chemical blogspace
aggregates blog posts from cheminformaticians, providing
a platform for discussion of algorithms, theory, within
a larger community than that of a single project.}
\label{fig:cb}
\end{figure}

Blog planets and aggregators play an important role here.
Various cheminformatics projects have blog planets, where
the blogs from developers and users from the community
around that project are aggregated. For example, the
Chemistry Development Kit and Bioclipse have planets
at respectively \url{http://pele.farmbio.uu.se/planetcdk/} and
\url{planet.bioclipse.net}.
Aggregators also aggregate blogs, but not necessarily around
a specific developer or user community. One such website
that aggregates cheminformatics blogs is Chemical blogspace
(see Figure~\ref{fig:cb}).

A similar role is played by Question \& Answer websites, a new
type of communication channel popularized by
StackOverflow~\cite{url:stackoverflow}. This communication
concept is used, for example, by a the Blue Obelisk
eXchange at \url{http://blueobelisk.shapado.com/}
(see Figure~\ref{fig:shapado}) where
people can ask question on how to use a particular
cheminformatics library, or how to solve a particular
problem. These sites essentially extend the concept of Frequently
Asked Question (FAQ) documents, except that they are grown and
maintained by a community rather than a single person. In addition,
novel mechanisms such as merit points and badges and the ability to
up vote (or down vote) for answers provide a ``social incentive'' to
the users of such sites to engage in the community (as opposed to
simply taking information, a.k.a., leeching).

\begin{figure}[bt]
\begin{center}
\includegraphics[width=0.8\textwidth]{graphics/boShapado.png}
\end{center}
\caption{The Blue Obelisk eXchange Question \& Answer
website is an open platform where people can ask questions regarding
the use cheminformatics software, or ask for solutions
to a problem they post.}
\label{fig:shapado}
\end{figure}

The technologies discussed so far have focused on communication
between members of a collaboration and other interested parties. But
another vital aspect of collaborative projects is the development of
documentation - ranging from API documentation to tutorials and policy
documents. While one could exchange documents via email, one very
quickly runs into the problem of keeping everybody's editions
synchronized. Collaborative document editing systems have recently
been developed that directly address this problem. One example is
Google Docs, which is an online resource that allows one to create
documents, spreadsheets and presentations and then share them between
other users. Each authorized user can edit the document and more
importantly, multiple users can simultaneously work on these
documents. The service automatically tracks the edits by each users and
provides an intuitive view of the document history, allowing one to
view the edits made by each user. The documents can be exported to a
variety of common formats, allowing one to introduce such documents
into the traditional workflow.

Google Docs is a useful solution to the problem of collaborative
editing of traditional documents. Wikis provide another approach, that
is more free-form. The fundamental idea of a wiki is that it is a
collection of pages, linked via hyperlinks and that authorized users
can edit, add to or delete these pages arbitrarily. Most wikis will
also keep a history of the edits made to each page, allowing one to
track who did what and when. 

Additionally, it is possible to add supplementary files to a wiki,
which allows one to record and track the entire state of a project
over time (cf. the Open Notebook Science Solubility Challenge on
Wikispaces~\cite{ons:exp34}). While wikis are useful they are not necessarily the
best solution for all cases. For example, in software development
projects, keeping an associated wiki up to date with the state of the
project can be tedious, especially if the development is very
rapid. While the wiki might be useful for material such as tutorials
and so on, it is rarely a good solution for API documentation. Many
would argue that even usage information should be a part of the API
documentation and should be written inline with the code. Such inline
documentation can easily be extracted and formatted using tools such
as Doxygen~\cite{url:doxygen} or Sphinx~\cite{url:sphinx}
and \emph{linked to} from the wiki. This last
point highlights one advantage of a wiki type of system - it is a very
easy way to aggregate resources via linking rather than include them
directly in the wiki itself. This leads to significantly lower efforts
in maintaining the wiki.

In addition to these systems, tools that have traditionally been
focused on software development can be usefully applied to other
scenarios. A good example is the use of a bug tracking systems to keep
track of feature requests or new ideas. These systems allow one to
keep a list of these issues and possibly assign them to one or more
people for followup.

It should be noted that the software systems to support the ideas
described here can be obtained in a variety of forms. Each component
described here can be obtained individually, require the collaboration
to set them up whereas more comprehensive solutions also exist that
couple wikis, feature tracking systems and collaborative editing
systems in a single package. In addition, one has a choice of Open
Source or commercial solutions to choose from.

We have discussed a variety of technologies that facilitate
collaborative project management. But a vital component of this is the
management of people within such projects. There are many approaches to
this ranging from committees to dictatorships (benevolent or
otherwise). In this chapter we do not discuss the merits or demerits
of any given approach, save to say that efficient personnel management
is vital to the successful completion of a collaborative project.

\section{Conclusion}

In this chapter we have discussed the various aspects of collaborative
cheminformatics. We have outlined tools available for software development,
building knowledge bases, and tools for collaborative computing.
We have also outlined the roles that Open Source, Open Data, and Open Standards
have in building successful collaborations, including the roles of
licensing as a social contract between collaborators, and communication
channels to discuss ideas. Similarly, we have shown how Open Standards
make it easier to build collaborative knowledge bases as they
provide a unified and clear-to-all interface to the data. We have
further described how collaborative computing, both locally and
remotely, can be established and how scientists can share high-level
workflow specifications.

As technologies continue to improve over the next few years, these kind of
collaborative cheminformatics uses will become easier and easier.
The cheminformatics applications outlined here merely present
a view on what will be possible

\bibliographystyle{unsrt}
\bibliography{chapter}

\end{document}

